{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.models import resnet18, resnet50\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from SSIM_PIL import compare_ssim\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = r\"path to data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:cuda\n"
     ]
    }
   ],
   "source": [
    "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device:{device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    def __init__(self, path):\n",
    "        self.pth = path\n",
    "        \n",
    "        self.hr_pth = os.path.join(self.pth, \"HR\")\n",
    "        self.lr_pth =os.path.join(self.pth, \"LR\")\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip()\n",
    "        ])\n",
    "    def __len__(self):\n",
    "        return len(self.hr_pth)\n",
    "    def __getitem__(self, idx):\n",
    "        hr_pth = os.path.join(self.hr_pth,os.listdir(self.hr_pth)[idx])\n",
    "        lr_pth = os.path.join(self.lr_pth, os.listdir(self.lr_pth)[idx])\n",
    "        hr_img, lr_img= np.load(hr_pth), np.load(lr_pth)\n",
    "        hr_img = torch.tensor(hr_img, dtype=torch.float32)\n",
    "        lr_img= torch.tensor(lr_img, dtype=torch.float32)\n",
    "        hr_img= self.transform(hr_img)\n",
    "        lr_img= self.transform(lr_img)\n",
    "        return hr_img, lr_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= dataset(pth)\n",
    "batch_size= 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.9 * len(data))\n",
    "test_size = len(data) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(data, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader= DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader= DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net= nn.Sequential(\n",
    "            nn.Conv2d(1, 64,kernel_size= 9, padding = 4, stride= 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 32, kernel_size= 1, padding = 0, stride= 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 1, kernel_size= 5, padding = 2, stride= 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_img(img):\n",
    "    img= F.interpolate(img, img.shape[2]*2, mode='bilinear', align_corners=False)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 75, 75])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= train_dataset[0][1]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SRCNN().to(device)\n",
    "epochs = 20\n",
    "lr1= 1e-4\n",
    "lr2= 1e-5\n",
    "loss_fn = nn.MSELoss().to(device)\n",
    "optimizer= torch.optim.SGD(\n",
    "    [\n",
    "        {'params': model.net[0].parameters(), 'lr': lr1},\n",
    "        {'params': model.net[2].parameters(), \"lr\":lr1},\n",
    "        {'params': model.net[4].parameters(), \"lr\":lr2}    \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_pth= r\"path to weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(weight_pth, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "Batch:0 | Loss:0.017433471977710724\n",
      "epoch: 2\n",
      "Batch:0 | Loss:0.01658250391483307\n",
      "epoch: 3\n",
      "Batch:0 | Loss:0.014951993711292744\n",
      "epoch: 4\n",
      "Batch:0 | Loss:0.017611544579267502\n",
      "epoch: 5\n",
      "Batch:0 | Loss:0.016232216730713844\n",
      "epoch: 6\n",
      "Batch:0 | Loss:0.015912851318717003\n",
      "epoch: 7\n",
      "Batch:0 | Loss:0.014369502663612366\n",
      "epoch: 8\n",
      "Batch:0 | Loss:0.01652359776198864\n",
      "epoch: 9\n",
      "Batch:0 | Loss:0.015605289489030838\n",
      "epoch: 10\n",
      "Batch:0 | Loss:0.016770128160715103\n",
      "epoch: 11\n",
      "Batch:0 | Loss:0.015839798375964165\n",
      "epoch: 12\n",
      "Batch:0 | Loss:0.01557568646967411\n",
      "epoch: 13\n",
      "Batch:0 | Loss:0.015284288674592972\n",
      "epoch: 14\n",
      "Batch:0 | Loss:0.016293812543153763\n",
      "epoch: 15\n",
      "Batch:0 | Loss:0.01557729672640562\n",
      "epoch: 16\n",
      "Batch:0 | Loss:0.017661597579717636\n",
      "epoch: 17\n",
      "Batch:0 | Loss:0.01477002538740635\n",
      "epoch: 18\n",
      "Batch:0 | Loss:0.015736624598503113\n",
      "epoch: 19\n",
      "Batch:0 | Loss:0.016701694577932358\n",
      "epoch: 20\n",
      "Batch:0 | Loss:0.01566552370786667\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f\"epoch: {epoch+1}\")\n",
    "    for batch, (hr, lr) in enumerate(train_loader):\n",
    "        lr= lr.to(device)\n",
    "        hr= hr.to(device)\n",
    "        upscaled= upscale_img(lr)\n",
    "        y_cap= model(upscaled)\n",
    "        loss= loss_fn(y_cap, hr)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if batch%100==0:\n",
    "            print(f\"Batch:{batch} | Loss:{loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvtToImage(img):\n",
    "    image= torch.permute(img, (1,2,0))\n",
    "    image=image.squeeze(-1)\n",
    "    image= np.asarray((image+1)*127.5, dtype=np.uint8)#.astype(np.uint8)\n",
    "    return image\n",
    "def Psnr(mse):\n",
    "    return 10*torch.log10(255**2/ torch.tensor(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.018980421125888824 | PSNR: 65.34774017333984\n"
     ]
    }
   ],
   "source": [
    "size= len(test_loader)\n",
    "test_loss= 0\n",
    "psnr=0\n",
    "final_img= []\n",
    "hr_img=[]\n",
    "with torch.no_grad():\n",
    "    for hr,lr in test_loader:\n",
    "        lr= lr.to(device)\n",
    "        hr= hr.to(device)\n",
    "        upscaled= upscale_img(lr)\n",
    "        sr= model(upscaled)\n",
    "        test_loss+=loss_fn(sr, hr).item()\n",
    "        psnr+= Psnr(test_loss)\n",
    "        final_img.append(sr)\n",
    "        hr_img.append(hr)\n",
    "psnr/= size\n",
    "test_loss/=size\n",
    "print(f\"Loss: {test_loss} | PSNR: {psnr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_img= []\n",
    "GT_img= []\n",
    "for i in final_img:\n",
    "    for j in i:\n",
    "       sr_img.append(j)\n",
    "\n",
    "for i in hr_img:\n",
    "    for j in i:\n",
    "      GT_img.append(j)\n",
    "\n",
    "img_a= sr_img[1].cpu().squeeze(0)\n",
    "img_b= GT_img[1].cpu().squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.018980421125888824 | PSNR: 65.34774017333984 | Average SSIM: 0.8911372193576739\n"
     ]
    }
   ],
   "source": [
    "ssim =0\n",
    "for sr, gt in zip(sr_img, GT_img):\n",
    "    sr= sr.cpu()\n",
    "    hr= gt.cpu()\n",
    "    sr_pil= Image.fromarray(cvtToImage(sr))\n",
    "    hr_pil = Image.fromarray(cvtToImage(hr))\n",
    "    ssim+= compare_ssim(sr_pil, hr_pil, GPU= False)\n",
    "ssim/= len(sr_img)\n",
    "print(f\"Loss: {test_loss} | PSNR: {psnr} | Average SSIM: {ssim}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
