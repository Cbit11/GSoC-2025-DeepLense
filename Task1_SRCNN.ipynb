{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet50\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "from skimage.metrics import peak_signal_noise_ratio as PSNR\n",
    "from SSIM_PIL import compare_ssim\n",
    "from PIL import Image\n",
    "data_pth = r\"Path\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:cuda\n"
     ]
    }
   ],
   "source": [
    "device= \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device:{device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pth, hr_pth = os.path.join(data_pth, os.listdir(data_pth)[2]),os.path.join(data_pth, os.listdir(data_pth)[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_hr_data(lr_pth, hr_pth):\n",
    "    lr_samples= os.listdir(lr_pth)\n",
    "    hr_samples= os.listdir(hr_pth)\n",
    "    data= []\n",
    "    for i, j in zip(lr_samples, hr_samples):\n",
    "        data.append([os.path.join(lr_pth, i),os.path.join(hr_pth, j) ])\n",
    "    return data\n",
    "lr_hr_data= lr_hr_data(lr_pth, hr_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "        x_min, x_max= x.min(), x.max()\n",
    "        x_norm= (x-x_min)/(x_max-x_min)\n",
    "        return x_norm\n",
    "\n",
    "class dataset:\n",
    "    def __init__(self, data, lr_dim, hr_dim):\n",
    "        self.data= data\n",
    "        self.lr_dim = lr_dim\n",
    "        self.hr_dim = hr_dim \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        lr_img, hr_img= np.load(self.data[idx][0]),np.load(self.data[idx][1])\n",
    "        lr_img= np.reshape(lr_img, (self.lr_dim, self.lr_dim, 1))\n",
    "        hr_img= np.reshape(hr_img, (self.hr_dim, self.hr_dim, 1))\n",
    "        lr_img= cv2.equalizeHist(((lr_img+1)*127.5).astype(np.uint8))\n",
    "        hr_img= cv2.equalizeHist(((hr_img+1)*127.5).astype(np.uint8))\n",
    "        lr_img= normalize(lr_img)\n",
    "        hr_img= normalize(hr_img)\n",
    "        lr_img =  np.reshape(lr_img, (1, self.lr_dim, self.lr_dim))\n",
    "        lr_img = torch.tensor(lr_img, dtype = torch.float32)\n",
    "        hr_img =  np.reshape(hr_img, (1, self.hr_dim, self.hr_dim))\n",
    "        hr_img = torch.tensor(hr_img, dtype = torch.float32)\n",
    "        return lr_img, hr_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net= nn.Sequential(\n",
    "            nn.Conv2d(1, 64,kernel_size= 9, padding = 4, stride= 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 32, kernel_size= 1, padding = 0, stride= 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 1, kernel_size= 5, padding = 2, stride= 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_img(img):\n",
    "    img= F.interpolate(img, img.shape[2]*2, mode='bilinear', align_corners=False)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SRCNN().to(device)\n",
    "epochs = 20\n",
    "lr1= 1e-4\n",
    "lr2= 1e-5\n",
    "loss_fn = nn.MSELoss().to(device)\n",
    "optimizer= torch.optim.SGD(\n",
    "    [\n",
    "        {'params': model.net[0].parameters(), 'lr': lr1},\n",
    "        {'params': model.net[2].parameters(), \"lr\":lr1},\n",
    "        {'params': model.net[4].parameters(), \"lr\":lr2}    \n",
    "    ]\n",
    ")\n",
    "batch_size= 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= dataset(lr_hr_data, 75, 150)\n",
    "train_data, val_data= torch.utils.data.random_split(data,[8000,2000])\n",
    "train_loader= DataLoader(train_data, batch_size= batch_size, shuffle=True)\n",
    "val_loader= DataLoader(val_data, batch_size, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "Batch:0 | Loss:0.4336123764514923\n",
      "Batch:100 | Loss:0.41895008087158203\n",
      "Batch:200 | Loss:0.4006974995136261\n",
      "epoch: 2\n",
      "Batch:0 | Loss:0.39290887117385864\n",
      "Batch:100 | Loss:0.37684518098831177\n",
      "Batch:200 | Loss:0.3556709587574005\n",
      "epoch: 3\n",
      "Batch:0 | Loss:0.3494839370250702\n",
      "Batch:100 | Loss:0.332652747631073\n",
      "Batch:200 | Loss:0.31448403000831604\n",
      "epoch: 4\n",
      "Batch:0 | Loss:0.30587702989578247\n",
      "Batch:100 | Loss:0.2906138002872467\n",
      "Batch:200 | Loss:0.2727082371711731\n",
      "epoch: 5\n",
      "Batch:0 | Loss:0.2697928547859192\n",
      "Batch:100 | Loss:0.25124868750572205\n",
      "Batch:200 | Loss:0.23619206249713898\n",
      "epoch: 6\n",
      "Batch:0 | Loss:0.23225603997707367\n",
      "Batch:100 | Loss:0.21591514348983765\n",
      "Batch:200 | Loss:0.20129628479480743\n",
      "epoch: 7\n",
      "Batch:0 | Loss:0.1911613494157791\n",
      "Batch:100 | Loss:0.17715024948120117\n",
      "Batch:200 | Loss:0.16523927450180054\n",
      "epoch: 8\n",
      "Batch:0 | Loss:0.15516677498817444\n",
      "Batch:100 | Loss:0.1416490525007248\n",
      "Batch:200 | Loss:0.12740465998649597\n",
      "epoch: 9\n",
      "Batch:0 | Loss:0.11900666356086731\n",
      "Batch:100 | Loss:0.10623139142990112\n",
      "Batch:200 | Loss:0.09754551947116852\n",
      "epoch: 10\n",
      "Batch:0 | Loss:0.08929642289876938\n",
      "Batch:100 | Loss:0.08144210278987885\n",
      "Batch:200 | Loss:0.07133696973323822\n",
      "epoch: 11\n",
      "Batch:0 | Loss:0.06732181459665298\n",
      "Batch:100 | Loss:0.05998368561267853\n",
      "Batch:200 | Loss:0.05209093540906906\n",
      "epoch: 12\n",
      "Batch:0 | Loss:0.047645628452301025\n",
      "Batch:100 | Loss:0.04601429030299187\n",
      "Batch:200 | Loss:0.04018660634756088\n",
      "epoch: 13\n",
      "Batch:0 | Loss:0.037722550332546234\n",
      "Batch:100 | Loss:0.033719178289175034\n",
      "Batch:200 | Loss:0.032466161996126175\n",
      "epoch: 14\n",
      "Batch:0 | Loss:0.029516270384192467\n",
      "Batch:100 | Loss:0.028515586629509926\n",
      "Batch:200 | Loss:0.02734309434890747\n",
      "epoch: 15\n",
      "Batch:0 | Loss:0.025454353541135788\n",
      "Batch:100 | Loss:0.02515522576868534\n",
      "Batch:200 | Loss:0.024608230218291283\n",
      "epoch: 16\n",
      "Batch:0 | Loss:0.02266664430499077\n",
      "Batch:100 | Loss:0.022098861634731293\n",
      "Batch:200 | Loss:0.021463708952069283\n",
      "epoch: 17\n",
      "Batch:0 | Loss:0.021610014140605927\n",
      "Batch:100 | Loss:0.022305207327008247\n",
      "Batch:200 | Loss:0.022034768015146255\n",
      "epoch: 18\n",
      "Batch:0 | Loss:0.020307550206780434\n",
      "Batch:100 | Loss:0.021330544725060463\n",
      "Batch:200 | Loss:0.02026602439582348\n",
      "epoch: 19\n",
      "Batch:0 | Loss:0.020606961101293564\n",
      "Batch:100 | Loss:0.020788954570889473\n",
      "Batch:200 | Loss:0.02059740386903286\n",
      "epoch: 20\n",
      "Batch:0 | Loss:0.02108113095164299\n",
      "Batch:100 | Loss:0.020749926567077637\n",
      "Batch:200 | Loss:0.021504849195480347\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f\"epoch: {epoch+1}\")\n",
    "    for batch, (lr, hr) in enumerate(train_loader):\n",
    "        lr= lr.to(device)\n",
    "        hr= hr.to(device)\n",
    "        upscaled= upscale_img(lr)\n",
    "        y_cap= model(upscaled)\n",
    "        loss= loss_fn(y_cap, hr)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if batch%100==0:\n",
    "            print(f\"Batch:{batch} | Loss:{loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvtToImage(img):\n",
    "    image= torch.permute(img, (1,2,0))\n",
    "    image= image.squeeze(-1)\n",
    "    image= np.asarray((image+1)*127.5,dtype= np.uint8)\n",
    "    return image\n",
    "def Psnr(mse):\n",
    "    return 10*torch.log10(255**2/ torch.tensor(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.02073234266468457 | PSNR: 51.09543991088867\n"
     ]
    }
   ],
   "source": [
    "size= len(val_loader)\n",
    "test_loss= 0\n",
    "psnr=0\n",
    "final_img= []\n",
    "hr_img=[]\n",
    "with torch.no_grad():\n",
    "    for lr,hr in val_loader:\n",
    "        lr= lr.to(device)\n",
    "        hr= hr.to(device)\n",
    "        upscaled= upscale_img(lr)\n",
    "        sr= model(upscaled)\n",
    "        test_loss+=loss_fn(sr, hr).item()\n",
    "        psnr+= Psnr(test_loss)\n",
    "        final_img.append(sr)\n",
    "        hr_img.append(hr)\n",
    "psnr/= size\n",
    "test_loss/=size\n",
    "print(f\"Loss: {test_loss} | PSNR: {psnr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"Srcnn_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_img= []\n",
    "GT_img= []\n",
    "for i in final_img:\n",
    "    for j in i:\n",
    "       sr_img.append(j)\n",
    "\n",
    "for i in hr_img:\n",
    "    for j in i:\n",
    "      GT_img.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_a= sr_img[1].cpu().squeeze(0)\n",
    "img_b= GT_img[1].cpu().squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.02073234266468457 | PSNR: 51.09543991088867 | Average SSIM: 0.43656901973842915\n"
     ]
    }
   ],
   "source": [
    "ssim =0\n",
    "for sr, gt in zip(sr_img, GT_img):\n",
    "    sr= sr.cpu()\n",
    "    hr= gt.cpu()\n",
    "    sr_pil= Image.fromarray(cvtToImage(sr))\n",
    "    hr_pil = Image.fromarray(cvtToImage(hr))\n",
    "    ssim+= compare_ssim(sr_pil, hr_pil, GPU= False)\n",
    "ssim/= len(sr_img)\n",
    "print(f\"Loss: {test_loss} | PSNR: {psnr} | Average SSIM: {ssim}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
